
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>解决问题： Pywin32 安装后出现 Import Win32api ImportError DLL Load Failed - AoboSir 博客</title>
  <meta name="author" content="Aobo Jaing">

  
  <meta name="description" content="执行 scrapy bench 命令时 出现错误。（之前安装了pywin32库） 1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://aobojaing.github.io/blog/2016/11/26/solve-pywin32-import-win32api-ImportError-DLL-load-failed/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/git@github.com:AoboJaing/atom.xml" rel="alternate" title="AoboSir 博客" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//libs.baidu.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->


  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">AoboSir 博客</a></h1>
  
    <h2>守候为了三世的臣子，话说我觉醒在这一代。祖先为我起的名字，注定我将文武全才。代码划分了我的世界，从老子出生起就打算征服天地。</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/git@github.com:AoboJaing/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.baidu.com" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="aobojaing.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="http://blog.csdn.net/github_35160620">CSDN</a></li>
  <li><a href="/aboutme">About Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">解决问题： Pywin32 安装后出现 Import Win32api ImportError DLL Load Failed</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-11-26T07:04:25+08:00'><span class='date'><span class='date-month'>Nov</span> <span class='date-day'>26</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>7:04 am</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><hr />

<p>执行 <code>scrapy bench</code> 命令时 出现错误。（之前安装了pywin32库）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Traceback (most recent call last):
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\twisted\internet\defer.py", line 1260, in _inlineCallbacks
</span><span class='line'>    result = g.send(result)
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\scrapy\crawler.py", line 72, in crawl
</span><span class='line'>    self.engine = self._create_engine()
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\scrapy\crawler.py", line 97, in _create_engine
</span><span class='line'>    return ExecutionEngine(self, lambda _: self.stop())
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\scrapy\core\engine.py", line 68, in __init__
</span><span class='line'>    self.downloader = downloader_cls(crawler)
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
</span><span class='line'>    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
</span><span class='line'>    return cls.from_settings(crawler.settings, crawler)
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
</span><span class='line'>    mwcls = load_object(clspath)
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
</span><span class='line'>    mod = import_module(module)
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\importlib\__init__.py", line 126, in import_module
</span><span class='line'>    return _bootstrap._gcd_import(name[level:], package, level)
</span><span class='line'>  File "&lt;frozen importlib._bootstrap&gt;", line 986, in _gcd_import
</span><span class='line'>  File "&lt;frozen importlib._bootstrap&gt;", line 969, in _find_and_load
</span><span class='line'>  File "&lt;frozen importlib._bootstrap&gt;", line 958, in _find_and_load_unlocked
</span><span class='line'>  File "&lt;frozen importlib._bootstrap&gt;", line 673, in _load_unlocked
</span><span class='line'>  File "&lt;frozen importlib._bootstrap_external&gt;", line 662, in exec_module
</span><span class='line'>  File "&lt;frozen importlib._bootstrap&gt;", line 222, in _call_with_frames_removed
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 23, in &lt;module&gt;
</span><span class='line'>    from scrapy.xlib.tx import ResponseFailed
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\scrapy\xlib\tx\__init__.py", line 3, in &lt;module&gt;
</span><span class='line'>    from twisted.web import client
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\twisted\web\client.py", line 42, in &lt;module&gt;
</span><span class='line'>    from twisted.internet.endpoints import TCP4ClientEndpoint, SSL4ClientEndpoint
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\twisted\internet\endpoints.py", line 36, in &lt;module&gt;
</span><span class='line'>    from twisted.internet.stdio import StandardIO, PipeAddress
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\twisted\internet\stdio.py", line 30, in &lt;module&gt;
</span><span class='line'>    from twisted.internet import _win32stdio
</span><span class='line'>  File "c:\users\aobo\appdata\local\programs\python\python35\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in &lt;module&gt;
</span><span class='line'>    import win32api
</span><span class='line'>ImportError: DLL load failed: 找不到指定的模块。</span></code></pre></td></tr></table></div></figure>


<h2>解决办法：</h2>

<p>参考网站：</p>

<p><a href="http://blog.csdn.net/mtt_sky/article/details/50445938">http://blog.csdn.net/mtt_sky/article/details/50445938</a>
<a href="http://blog.sina.com.cn/s/blog_5a81b7990101l225.html">http://blog.sina.com.cn/s/blog_5a81b7990101l225.html</a></p>

<p><code>C:\Users\AOBO\AppData\Local\Programs\Python\Python35\Lib\site-packages\pywin32_system32</code></p>

<p>里面的所有的文件复制到：<code>C:\Windows\System32</code></p>

<p>现在，问题解决。无需重新打开DOS窗口，直接执行：<code>scrapy bench</code>。</p>

<p>输出正常：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>D:\BaiduYunDownload\first&gt;scrapy bench
</span><span class='line'>2016-11-23 13:56:45 [scrapy] INFO: Scrapy 1.2.1 started (bot: first)
</span><span class='line'>2016-11-23 13:56:45 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'first.spiders', 'CLOSESPIDER_TIMEOUT': 10, 'LOGSTATS_INTERVAL': 1, 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'first', 'SPIDER_MODULES': ['first.spiders']}
</span><span class='line'>2016-11-23 13:56:47 [scrapy] INFO: Enabled extensions:
</span><span class='line'>['scrapy.extensions.corestats.CoreStats',
</span><span class='line'> 'scrapy.extensions.telnet.TelnetConsole',
</span><span class='line'> 'scrapy.extensions.closespider.CloseSpider',
</span><span class='line'> 'scrapy.extensions.logstats.LogStats']
</span><span class='line'>2016-11-23 13:56:48 [scrapy] INFO: Enabled downloader middlewares:
</span><span class='line'>['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
</span><span class='line'> 'scrapy.downloadermiddlewares.stats.DownloaderStats']
</span><span class='line'>2016-11-23 13:56:48 [scrapy] INFO: Enabled spider middlewares:
</span><span class='line'>['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
</span><span class='line'> 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
</span><span class='line'> 'scrapy.spidermiddlewares.referer.RefererMiddleware',
</span><span class='line'> 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
</span><span class='line'> 'scrapy.spidermiddlewares.depth.DepthMiddleware']
</span><span class='line'>2016-11-23 13:56:48 [scrapy] INFO: Enabled item pipelines:
</span><span class='line'>['first.pipelines.FirstPipeline']
</span><span class='line'>2016-11-23 13:56:48 [scrapy] INFO: Spider opened
</span><span class='line'>2016-11-23 13:56:48 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:49 [scrapy] INFO: Crawled 69 pages (at 4140 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:50 [scrapy] INFO: Crawled 141 pages (at 4320 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:51 [scrapy] INFO: Crawled 205 pages (at 3840 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:52 [scrapy] INFO: Crawled 269 pages (at 3840 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:53 [scrapy] INFO: Crawled 325 pages (at 3360 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:54 [scrapy] INFO: Crawled 373 pages (at 2880 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:55 [scrapy] INFO: Crawled 429 pages (at 3360 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:56 [scrapy] INFO: Crawled 477 pages (at 2880 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:57 [scrapy] INFO: Crawled 533 pages (at 3360 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:58 [scrapy] INFO: Crawled 581 pages (at 2880 pages/min), scraped 0 items (at 0 items/min)
</span><span class='line'>2016-11-23 13:56:58 [scrapy] INFO: Closing spider (closespider_timeout)
</span><span class='line'>2016-11-23 13:56:59 [scrapy] INFO: Dumping Scrapy stats:
</span><span class='line'>{'downloader/request_bytes': 265444,
</span><span class='line'> 'downloader/request_count': 597,
</span><span class='line'> 'downloader/request_method_count/GET': 597,
</span><span class='line'> 'downloader/response_bytes': 1833261,
</span><span class='line'> 'downloader/response_count': 597,
</span><span class='line'> 'downloader/response_status_count/200': 597,
</span><span class='line'> 'finish_reason': 'closespider_timeout',
</span><span class='line'> 'finish_time': datetime.datetime(2016, 11, 23, 5, 56, 59, 266168),
</span><span class='line'> 'log_count/INFO': 17,
</span><span class='line'> 'request_depth_max': 20,
</span><span class='line'> 'response_received_count': 597,
</span><span class='line'> 'scheduler/dequeued': 597,
</span><span class='line'> 'scheduler/dequeued/memory': 597,
</span><span class='line'> 'scheduler/enqueued': 11938,
</span><span class='line'> 'scheduler/enqueued/memory': 11938,
</span><span class='line'> 'start_time': datetime.datetime(2016, 11, 23, 5, 56, 48, 450531)}
</span><span class='line'>2016-11-23 13:56:59 [scrapy] INFO: Spider closed (closespider_timeout)
</span><span class='line'>
</span><span class='line'>D:\BaiduYunDownload\first&gt;</span></code></pre></td></tr></table></div></figure>


<hr />
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Aobo Jaing</span></span>

      




<time class='entry-date' datetime='2016-11-26T07:04:25+08:00'><span class='date'><span class='date-month'>Nov</span> <span class='date-day'>26</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>7:04 am</span></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/python3-da-xing-wang-luo-pa-chong-shi-zhan/'>python3 大型网络爬虫实战</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
  
    <!-- JiaThis Button BEGIN -->
<div class="jiathis_style_32x32">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2016/11/26/python-Scrapy-command/" title="Previous Post: Python --- Scrapy 命令">&laquo; Python --- Scrapy 命令</a>
      
      
        <a class="basic-alignment right" href="/blog/2016/11/26/python3-UnicodeEncodeError-gbk-codec-can't-encode-character-xa0/" title="Next Post: Python3 解决编码问题：  `UnicodeEncodeError: 'gbk' codec can't encode character ' ' in position 10: illegal multibyte sequence` --- 当执行爬虫将爬取信息打印到终端时出现的编码错误">Python3 解决编码问题：  `UnicodeEncodeError: 'gbk' codec can't encode character ' ' in position 10: illegal multibyte sequence` --- 当执行爬虫将爬取信息打印到终端时出现的编码错误 &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="/blog/2016/11/26/solve-pywin32-import-win32api-ImportError-DLL-load-failed" data-title="解决问题： pywin32 安装后出现 import win32api ImportError  DLL load failed" data-url="http://aobojaing.github.io /blog/2016/11/26/solve-pywin32-import-win32api-ImportError-DLL-load-failed/"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"aobosir"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/11/29/Git-GitHub-001-For-Windows-download-install-tutorial/">Git(Github) 001 介绍和下载安装图文教程 for Windows</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/11/26/python3-large-web-crawler-002-scrapy-crawler-project-create-baidu-csdn/">Python3 大型网络爬虫实战 002 --- Scrapy 爬虫项目的创建及爬虫的创建 --- 实例：爬取百度标题和CSDN博客</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/11/26/python-xpath/">Python --- Xpath 表达式 --- Ongoing</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/11/26/python3-UnicodeEncodeError-gbk-codec-can't-encode-character-xa0/">Python3 解决编码问题： `UnicodeEncodeError: 'Gbk' Codec Can't Encode Character ' ' in Position 10: Illegal Multibyte Sequence` --- 当执行爬虫将爬取信息打印到终端时出现的编码错误</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/11/26/solve-pywin32-import-win32api-ImportError-DLL-load-failed/">解决问题： Pywin32 安装后出现 Import Win32api ImportError DLL Load Failed</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Tags</h1>
  <ul class="tag-cloud">
    <a style="font-size: 129%" href="/tags/auto-control/">Auto Control</a>
<a style="font-size: 115%" href="/tags/c-number/">C#</a>
<a style="font-size: 115%" href="/tags/git/">Git</a>
<a style="font-size: 115%" href="/tags/github/">GitHub</a>
<a style="font-size: 129%" href="/tags/octopress/">Octopress</a>
<a style="font-size: 90%" href="/tags/powercmd/">PowerCmd</a>
<a style="font-size: 210%" href="/tags/sql/">SQL</a>
<a style="font-size: 210%" href="/tags/sql-server/">SQL Server</a>
<a style="font-size: 129%" href="/tags/vs2015/">VS2015</a>
<a style="font-size: 129%" href="/tags/visual-studio-2015/">Visual Studio 2015</a>
<a style="font-size: 147%" href="/tags/windows/">Windows</a>
<a style="font-size: 90%" href="/tags/cross-join/">cross join</a>
<a style="font-size: 90%" href="/tags/from-where/">from where</a>
<a style="font-size: 90%" href="/tags/full-join/">full join</a>
<a style="font-size: 90%" href="/tags/group-by/">group by</a>
<a style="font-size: 90%" href="/tags/having/">having</a>
<a style="font-size: 90%" href="/tags/identity/">identity</a>
<a style="font-size: 90%" href="/tags/in/">in</a>
<a style="font-size: 90%" href="/tags/innor-join/">innor join</a>
<a style="font-size: 90%" href="/tags/join-on/">join on</a>
<a style="font-size: 90%" href="/tags/left-join/">left join</a>
<a style="font-size: 90%" href="/tags/order-by/">order by</a>
<a style="font-size: 129%" href="/tags/pip/">pip</a>
<a style="font-size: 139%" href="/tags/python/">python</a>
<a style="font-size: 139%" href="/tags/python3/">python3</a>
<a style="font-size: 90%" href="/tags/right-join/">right join</a>
<a style="font-size: 90%" href="/tags/union/">union</a>
<a style="font-size: 90%" href="/tags/zhu-jian/">主键</a>
<a style="font-size: 90%" href="/tags/shi-wu/">事务</a>
<a style="font-size: 115%" href="/tags/chuan-di-han-shu/">传递函数</a>
<a style="font-size: 115%" href="/tags/xin-hao-liu-tu/">信号流图</a>
<a style="font-size: 90%" href="/tags/nei-lian-jie/">内连接</a>
<a style="font-size: 90%" href="/tags/fen-zu/">分组</a>
<a style="font-size: 115%" href="/tags/dong-tai-jie-gou-tu/">动态结构图</a>
<a style="font-size: 115%" href="/tags/wei-fen-fang-cheng/">微分方程</a>
<a style="font-size: 115%" href="/tags/shu-xue-mo-xing/">数学模型</a>
<a style="font-size: 187%" href="/tags/cha-xun/">查询</a>
<a style="font-size: 90%" href="/tags/cha-xun-yu-ju-shun-xu/">查询语句顺序</a>
<a style="font-size: 115%" href="/tags/mo-hu-cha-xun/">模糊查询</a>
<a style="font-size: 115%" href="/tags/pa-chong/">爬虫</a>
<a style="font-size: 90%" href="/tags/ju-he-han-shu/">聚合函数</a>
<a style="font-size: 139%" href="/tags/zi-dong-kong-zhi-yuan-li/">自动控制原理</a>
<a style="font-size: 90%" href="/tags/shi-tu/">视图</a>
<a style="font-size: 115%" href="/tags/ruan-jian-an-zhuang/">软件安装</a>
<a style="font-size: 90%" href="/tags/lian-jie-cha-xun/">连接查询</a>

  </ul>
</section><section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/auto-control/'>auto control (4)</a></li>
<li class='category'><a href='/blog/categories/c-/'>c# (2)</a></li>
<li class='category'><a href='/blog/categories/eda/'>eda (1)</a></li>
<li class='category'><a href='/blog/categories/git-github/'>git_github (2)</a></li>
<li class='category'><a href='/blog/categories/python/'>python (2)</a></li>
<li class='category'><a href='/blog/categories/python3-大型网络爬虫实战/'>python3 大型网络爬虫实战 (7)</a></li>
<li class='category'><a href='/blog/categories/sql/'>sql (29)</a></li>
<li class='category'><a href='/blog/categories/sql-server/'>sql server (29)</a></li>
<li class='category'><a href='/blog/categories/use-octopress-build-blog-site/'>use octopress build blog site (3)</a></li>
<li class='category'><a href='/blog/categories/自动控制原理/'>自动控制原理 (4)</a></li>
<li class='category'><a href='/blog/categories/软件安装/'>软件安装 (4)</a></li>

  </ul>
</section>
  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Aobo Jaing -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
